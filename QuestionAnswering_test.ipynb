{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W266_HW/blob/main/QuestionAnswering_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqdTypiKjOCQ"
      },
      "source": [
        "# Assignment 3: Question Answering with a Language Model\n",
        "\n",
        "**Description:** This assignment covers question answering with a language model. There are many ways to formulate the question answering task and this is one of them.  You will use the masked token with T5 to develop a sentence construct that allows the model to answer the question more than 75% of the time. You should also be able to develop an intuition for:\n",
        "\n",
        "\n",
        "* Working with masked language models \n",
        "* Working with prompt based models \n",
        "* The depths and limits of knowledge in these large models \n",
        "\n",
        " \n",
        "This notebook does NOT require a GPU to work in a timely fashion. This notebook should be run on a Google Colab even though it does not require a GPU. By default, when you open the notebook in Colab it will not configure a GPU. \n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2023-spring-main/blob/master/assignment/a3/QuestionAnswering_test.ipynb)\n",
        "\n",
        "\n",
        "**INSTRUCTIONS:** \n",
        "\n",
        "* Questions are always indicated as **QUESTION:**, so you can search for this string to make sure you answered all of the questions. You are expected to fill out, run, and submit this notebook, as well as to answer the questions in the **answers** file as you did in a1 and a2.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "14QhwWvujXh-"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hldMurd9pnTl"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "phetFLjypnc9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pBWFf_-1pnxK"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9-jQ_zezZg7",
        "outputId": "f36e7036-92d3-417a-a139-9d457d7bf2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tft5_for_conditional_generation_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " shared (Embedding)          multiple                  24674304  \n",
            "                                                                 \n",
            " encoder (TFT5MainLayer)     multiple                  109628544 \n",
            "                                                                 \n",
            " decoder (TFT5MainLayer)     multiple                  137949312 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 222,903,552\n",
            "Trainable params: 222,903,552\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "t5_model = TFT5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "t5_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRvBDemGBBAp"
      },
      "source": [
        "\"\\<extra_id_0\\>\" is the special token we can use with T5 to invoke its masked word modeling ability.  This means we can construct sentences, like a fill in the blank test, that allow us to probe the knowledge embedded in the model based on its pre-training.  Here's an example that works well.  We can construct with the special token a prompt sentence that says \"A poodle is a type of \"\\<extra_id_0\\>\"\".  We expect the model to fill in the word 'dog' as it predicts the missing word.  Note that it may also predict 'pet' as another possibility as a poodle can be a type of pet.  Remember the \n",
        "\"\\<extra_id_0\\>\" token can appear anywhere in the sentence, not just at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt6yMNk5pnzG",
        "outputId": "8e1d1f9a-2197-4125-91b2-ae5c03bd2121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['poodle', 'dog', 'dog .']\n"
          ]
        }
      ],
      "source": [
        "PROMPT_SENTENCE = ( \"A poodle is a type of <extra_id_0> .\")\n",
        "t5_input_text = PROMPT_SENTENCE\n",
        "t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                   num_beams=9,\n",
        "                                   no_repeat_ngram_size=1,\n",
        "                                   num_return_sequences=3,\n",
        "                                   min_length=1,\n",
        "                                   max_length=5)\n",
        "                             \n",
        "print([t5_tokenizer.decode(g, skip_special_tokens=True, \n",
        "                           clean_up_tokenization_spaces=False) for g in t5_summary_ids])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_summary_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFyNKuy2GgjK",
        "outputId": "5d84eba5-08cd-40a0-c46f-a923029d63db"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
              "array([[    0, 32099,     3,   102, 14957],\n",
              "       [    0, 32099,  1782, 32098,     3],\n",
              "       [    0, 32099,  1782,     3,     5]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAKwWNoCUi6c",
        "outputId": "94ddff6d-6033-46cc-ba80-9ab77b0361ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Li', '.', '']\n"
          ]
        }
      ],
      "source": [
        "#Use this space to craft your first sentence.  You do NOT need to modify the hyperparameters!\n",
        "PROMPT_SENTENCE = ( \"<extra_id_0> Lily is a type of Lily.\")\n",
        "t5_input_text = PROMPT_SENTENCE\n",
        "t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                   num_beams=9,\n",
        "                                   no_repeat_ngram_size=2,\n",
        "                                   num_return_sequences=3,\n",
        "                                   min_length=1,\n",
        "                                   max_length=3)\n",
        "                             \n",
        "print([t5_tokenizer.decode(g, skip_special_tokens=True, \n",
        "                           clean_up_tokenization_spaces=False) for g in t5_summary_ids])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this space to craft your first sentence.  You do NOT need to modify the hyperparameters!\n",
        "PROMPT_SENTENCE = ( \"<extra_id_0> is a species of hamsters.\")\n",
        "t5_input_text = PROMPT_SENTENCE\n",
        "t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                   num_beams=9,\n",
        "                                   no_repeat_ngram_size=2,\n",
        "                                   num_return_sequences=3,\n",
        "                                   min_length=1,\n",
        "                                   max_length=3)\n",
        "                             \n",
        "print([t5_tokenizer.decode(g, skip_special_tokens=True, \n",
        "                           clean_up_tokenization_spaces=False) for g in t5_summary_ids])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj1NiPandlNr",
        "outputId": "8d2721ac-cff2-4cfb-d938-f33bb11c3596"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '.', 'ham']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this space to craft your first sentence.  You do NOT need to modify the hyperparameters!\n",
        "PROMPT_SENTENCE = ( \"<extra_id_0> in India is one of the seven wonders of the world.\")\n",
        "t5_input_text = PROMPT_SENTENCE\n",
        "t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                   num_beams=9,\n",
        "                                   no_repeat_ngram_size=2,\n",
        "                                   num_return_sequences=3,\n",
        "                                   min_length=1,\n",
        "                                   max_length=3)\n",
        "                             \n",
        "print([t5_tokenizer.decode(g, skip_special_tokens=True, \n",
        "                           clean_up_tokenization_spaces=False) for g in t5_summary_ids])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3IaEimodu7A",
        "outputId": "90cc80d3-1318-472c-f50d-e3d24c4b3392"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'India', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this space to craft your first sentence.  You do NOT need to modify the hyperparameters!\n",
        "PROMPT_SENTENCE = ( \"Who is the <extra_id_0> of the USA now?\")\n",
        "t5_input_text = PROMPT_SENTENCE\n",
        "t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                   num_beams=9,\n",
        "                                   no_repeat_ngram_size=2,\n",
        "                                   num_return_sequences=3,\n",
        "                                   min_length=1,\n",
        "                                   max_length=3)\n",
        "                             \n",
        "print([t5_tokenizer.decode(g, skip_special_tokens=True, \n",
        "                           clean_up_tokenization_spaces=False) for g in t5_summary_ids])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx2X335oeAlw",
        "outputId": "6c4f343a-931d-43eb-d71e-9d06ad97201a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['President', 'president', 'leader']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjEDY_mSTpqR"
      },
      "source": [
        "After you've run it once, try substituting 'beagle' for 'poodle' and you'll see the model gets confused.\n",
        "\n",
        "Notice too that we are using a beam search approach to generate multiple possibilities but only accept the top three choices rather than just the first choice. We're asking for three answer sequences to be returned and they should be between 1 and 5 subwords long.\n",
        "\n",
        "With the growth of text generation models, developing a good prompt is an increasingly important skill. \n",
        "\n",
        "**QUESTION:**\n",
        "\n",
        "1.1 Let's test the actual knowledge encoded in the T5 model. Let's construct prompts that return provably true or false facts like you might see on a fill in the blank test.  Given the following ten countries (England, France, Germany, Russia, Egypt, Thailand, Japan, Canada, India, China) construct **two** different PROMPT_SENTENCEs using the special token and the values of the countries list so that in at least 7 of the 10 cases one of the top three answers is a provably correct fact.  Use the string COUNTRY to stand in for each of the elements in the list.  For example, \"\\<extra_id_0\\> is the chief export of COUNTRY\".\n",
        "\n",
        "Note that a fact usually takes the form of a noun phrase - verb phrase - noun phrase triple where one of those noun phrases will consist of the country value.   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "country_list = ['England', 'France', 'Germany', 'Russia', 'Egypt', 'Thailand', 'Japan', 'Canada', 'India', 'China']\n",
        "PROMPT_SENTENCE1 = ( \"The capital of country_name is <extra_id_0>.\")\n",
        "PROMPT_SENTENCE2 = ( \"The official language of country_name is <extra_id_0>.\")"
      ],
      "metadata": {
        "id": "kN0tdNCaGLYJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this space to craft your second sentence.  You do NOT need to modify the hyperparameters!\n",
        "for country in country_list:\n",
        "    print(f\"Country : {country}\")\n",
        "\n",
        "    # Replacing the COUNTRY tag with the actual country name, and then show it\n",
        "    PROMPT_SENTENCE = PROMPT_SENTENCE1.replace(\"country_name\", country)\n",
        "    \n",
        "    print(f\"Prompt sentence : \\'{PROMPT_SENTENCE}\\'\")\n",
        "    \n",
        "    # Running the model\n",
        "    t5_input_text = PROMPT_SENTENCE\n",
        "    t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "    t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                       num_beams=9,\n",
        "                                       no_repeat_ngram_size=2,\n",
        "                                       num_return_sequences=3,\n",
        "                                       min_length=1,\n",
        "                                       max_length=3)\n",
        "    # Showing results\n",
        "    print(f\"Possible answers are: {[t5_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in t5_summary_ids]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDS1hlUZHtQ4",
        "outputId": "887c8d4e-f011-4d1f-f095-5caf589dc926"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country : England\n",
            "Prompt sentence : 'The capital of England is <extra_id_0>.'\n",
            "Possible answers are: ['London', 'Manchester', 'the']\n",
            "Country : France\n",
            "Prompt sentence : 'The capital of France is <extra_id_0>.'\n",
            "Possible answers are: ['Paris', 'Strasbourg', 'Marseille']\n",
            "Country : Germany\n",
            "Prompt sentence : 'The capital of Germany is <extra_id_0>.'\n",
            "Possible answers are: ['Berlin', 'Frankfurt', 'Hamburg']\n",
            "Country : Russia\n",
            "Prompt sentence : 'The capital of Russia is <extra_id_0>.'\n",
            "Possible answers are: ['Moscow', 'Kiev', 'the']\n",
            "Country : Egypt\n",
            "Prompt sentence : 'The capital of Egypt is <extra_id_0>.'\n",
            "Possible answers are: ['Cairo', 'Alexandria', 'Abu']\n",
            "Country : Thailand\n",
            "Prompt sentence : 'The capital of Thailand is <extra_id_0>.'\n",
            "Possible answers are: ['Bangkok', 'Phuket', 'Ph']\n",
            "Country : Japan\n",
            "Prompt sentence : 'The capital of Japan is <extra_id_0>.'\n",
            "Possible answers are: ['Tokyo', 'Kyoto', 'Nag']\n",
            "Country : Canada\n",
            "Prompt sentence : 'The capital of Canada is <extra_id_0>.'\n",
            "Possible answers are: ['Ottawa', 'Toronto', 'Montreal']\n",
            "Country : India\n",
            "Prompt sentence : 'The capital of India is <extra_id_0>.'\n",
            "Possible answers are: ['Mumbai', 'Kolkata', 'Delhi']\n",
            "Country : China\n",
            "Prompt sentence : 'The capital of China is <extra_id_0>.'\n",
            "Possible answers are: ['Beijing', 'Shanghai', 'Gu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "t5 model correctly specified the capital cities for all the countries present in the country list."
      ],
      "metadata": {
        "id": "Wt_7zZ-1Vj7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this space to craft your second sentence.  You do NOT need to modify the hyperparameters!\n",
        "for country in country_list:\n",
        "    print(f\"Country : {country}\")\n",
        "\n",
        "    # Replacing the COUNTRY tag with the actual country name, and then show it\n",
        "    PROMPT_SENTENCE = PROMPT_SENTENCE2.replace(\"country_name\", country)\n",
        "    \n",
        "    print(f\"Prompt sentence : \\'{PROMPT_SENTENCE}\\'\")\n",
        "    \n",
        "    # Running the model\n",
        "    t5_input_text = PROMPT_SENTENCE\n",
        "    t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')\n",
        "    t5_summary_ids = t5_model.generate(t5_inputs['input_ids'], \n",
        "                                       num_beams=9,\n",
        "                                       no_repeat_ngram_size=2,\n",
        "                                       num_return_sequences=3,\n",
        "                                       min_length=1,\n",
        "                                       max_length=3)\n",
        "    # Showing results\n",
        "    print(f\"Possible answers are: {[t5_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in t5_summary_ids]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNhBEOXXI_D2",
        "outputId": "20eaa400-2ec8-4a98-b770-bdfba93d50dd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country : England\n",
            "Prompt sentence : 'The official language of England is <extra_id_0>.'\n",
            "Possible answers are: ['English', 'english', 'Welsh']\n",
            "Country : France\n",
            "Prompt sentence : 'The official language of France is <extra_id_0>.'\n",
            "Possible answers are: ['French', 'English', 'Fran√ßais']\n",
            "Country : Germany\n",
            "Prompt sentence : 'The official language of Germany is <extra_id_0>.'\n",
            "Possible answers are: ['German', 'English', 'german']\n",
            "Country : Russia\n",
            "Prompt sentence : 'The official language of Russia is <extra_id_0>.'\n",
            "Possible answers are: ['Russian', 'English', '']\n",
            "Country : Egypt\n",
            "Prompt sentence : 'The official language of Egypt is <extra_id_0>.'\n",
            "Possible answers are: ['Arabic', 'English', 'Egyptian']\n",
            "Country : Thailand\n",
            "Prompt sentence : 'The official language of Thailand is <extra_id_0>.'\n",
            "Possible answers are: ['Thai', 'English', '']\n",
            "Country : Japan\n",
            "Prompt sentence : 'The official language of Japan is <extra_id_0>.'\n",
            "Possible answers are: ['English', 'Japanese', '']\n",
            "Country : Canada\n",
            "Prompt sentence : 'The official language of Canada is <extra_id_0>.'\n",
            "Possible answers are: ['English', 'French', 'Canadian']\n",
            "Country : India\n",
            "Prompt sentence : 'The official language of India is <extra_id_0>.'\n",
            "Possible answers are: ['Hindi', 'English', 'Tamil']\n",
            "Country : China\n",
            "Prompt sentence : 'The official language of China is <extra_id_0>.'\n",
            "Possible answers are: ['Chinese', 'Mandarin', 'English']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "t5 model correctly specified the official language for all the countries present in the country list."
      ],
      "metadata": {
        "id": "WCZPFIJrXDEa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}